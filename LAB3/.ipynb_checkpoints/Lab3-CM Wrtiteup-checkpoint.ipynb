{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "## Motion Capture Clustering\n",
    "\n",
    "### Team members: Luay Dajani, Dana Geislinger, Chris Morgan, Caroll Rodriguez\n",
    "##### Github - https://github.com/cdmorgan103/7331DataMiningNoShow\n",
    "\n",
    "MSDS 7331, 12/02/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset provides data on captured hand gestures using motion tracking sensors on various users gloves. This was done to properly model some of the different movements involved in making 5 different hand gestures (.\n",
    "\n",
    "From a business perspective, we'd like to model the different locations of the sensors and see if we can properly cluster the different sensors with enough seperation relative to there x,y,& z coordinates.\n",
    "\n",
    "To measure effectiveness of our clustering, we will be examining the Silhouette for the different clustering algorithms we will examine for this dataset. While clustering could be combined with the usage of other modeling techniques, we are primarily going to be examing clustering itself for this particular datset so we can better understand how much variance actually occurs within the data as a whole and relative to the variance caused by different users and gestures.\n",
    "\n",
    "Considering that our business user will need to better understand different positioning information for sensor utilization, this will allow stakeholders to have an additional approximation tool for determining what part of the hand is in what location of the area. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data is provided in the form of a CSV file. A header provides the name of each attribute for our dataset and a question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system for the motion capped equiped glove/hand.  Each variable is explained in greater detail in the table below and data can be found at the following link.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Motion+Capture+Hand+Postures#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Dataset\n",
    "\n",
    "| Variable Name  | Data Type | Variable Type         | Description                                                             |\n",
    "| -------------- | --------- | --------------------- | ----------------------------------------------------------------------- |\n",
    "| Class          | Nominal  | Identifier            | Classifier for hand gesture made scaled 1 to 5 (1=Fist, 2=Stop, 3=Point1 finger, 4=Point 2 fingers, 5=Grab)                                 |\n",
    "| User           | Nominal | Identifier            | ID number representing 15 different test users (scaled 0 to 14)| \n",
    "| Xi (0-11) | Interval  | Integer        | Measures distance in milimeters on the x axis for the 'i'th sensor (0-11) |\n",
    "| Yi (0-11) | Interval  | Integer        | Measures distance in milimeters on the y axis for the 'i'th sensor (0-11) |\n",
    "| Zi (0-11) | Interval  | Integer     | Measures distance in milimeters on the z axis for the 'i'th sensor (0-11) |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Because our data is 3 dimensional, a transformation of our dataset was required to adequately cluster the data in a 3 dimensional space.\n",
    "\n",
    "\n",
    "#### Final Dataset\n",
    "| Variable Name  | Data Type | Variable Type         | Description                                                             |\n",
    "| -------------- | --------- | --------------------- | ----------------------------------------------------------------------- |\n",
    "| Class          | Nominal  | Identifier            | Classifier for hand gesture made scaled 1 to 5 (1=Fist, 2=Stop, 3=Point1 finger, 4=Point 2 fingers, 5=Grab)                                 |\n",
    "| User           | Nominal | Identifier            | ID number representing 15 different test users (scaled 0 to 14)| \n",
    "| Sensor    | Nominal  | Identifier       | Sensor identifier (sensors labeled 0-11) |\n",
    "| X         | Interval  | Integer        | Measures distance in milimeters on the x axis for sensor location |\n",
    "| Y         | Interval  | Integer        | Measures distance in milimeters on the y axis  for sensor location |\n",
    "| Z         | Interval  | Integer     | Measures distance in milimeters on the z axis  for sensor location|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record, so it is possible for sensors to be in different positions from run to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing\n",
    "To get started, we'll load in our dataset and check the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78096 entries, 0 to 78095\n",
      "Data columns (total 38 columns):\n",
      "Class    78096 non-null int64\n",
      "User     78096 non-null int64\n",
      "X0       78096 non-null float64\n",
      "Y0       78096 non-null float64\n",
      "Z0       78096 non-null float64\n",
      "X1       78096 non-null float64\n",
      "Y1       78096 non-null float64\n",
      "Z1       78096 non-null float64\n",
      "X2       78096 non-null float64\n",
      "Y2       78096 non-null float64\n",
      "Z2       78096 non-null float64\n",
      "X3       78096 non-null object\n",
      "Y3       78096 non-null object\n",
      "Z3       78096 non-null object\n",
      "X4       78096 non-null object\n",
      "Y4       78096 non-null object\n",
      "Z4       78096 non-null object\n",
      "X5       78096 non-null object\n",
      "Y5       78096 non-null object\n",
      "Z5       78096 non-null object\n",
      "X6       78096 non-null object\n",
      "Y6       78096 non-null object\n",
      "Z6       78096 non-null object\n",
      "X7       78096 non-null object\n",
      "Y7       78096 non-null object\n",
      "Z7       78096 non-null object\n",
      "X8       78096 non-null object\n",
      "Y8       78096 non-null object\n",
      "Z8       78096 non-null object\n",
      "X9       78096 non-null object\n",
      "Y9       78096 non-null object\n",
      "Z9       78096 non-null object\n",
      "X10      78096 non-null object\n",
      "Y10      78096 non-null object\n",
      "Z10      78096 non-null object\n",
      "X11      78096 non-null object\n",
      "Y11      78096 non-null object\n",
      "Z11      78096 non-null object\n",
      "dtypes: float64(9), int64(2), object(27)\n",
      "memory usage: 22.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from pprint import pprint\n",
    "#from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_columns\",100)\n",
    "\n",
    "# Load the data into variable 'df'\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/cdmorgan103/7331DataMiningNoShow/master/LAB3/Postures.csv')\n",
    "\n",
    "# Get an overview of the raw data\n",
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will remove class 0 \n",
    "df = df[df.Class !=0 ]\n",
    "\n",
    "#change ? to none to improve data format\n",
    "df=df.replace({'?': 'NaN'})\n",
    "\n",
    "#coerces into numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>User</th>\n",
       "      <th>X0</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Z0</th>\n",
       "      <th>X1</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Z1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Z2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Z3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Z4</th>\n",
       "      <th>X5</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Z5</th>\n",
       "      <th>X6</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Z6</th>\n",
       "      <th>X7</th>\n",
       "      <th>Y7</th>\n",
       "      <th>Z7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y8</th>\n",
       "      <th>Z8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y9</th>\n",
       "      <th>Z9</th>\n",
       "      <th>X10</th>\n",
       "      <th>Y10</th>\n",
       "      <th>Z10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Y11</th>\n",
       "      <th>Z11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.263880</td>\n",
       "      <td>71.466776</td>\n",
       "      <td>-64.807709</td>\n",
       "      <td>76.895635</td>\n",
       "      <td>42.462500</td>\n",
       "      <td>-72.780545</td>\n",
       "      <td>36.621229</td>\n",
       "      <td>81.680557</td>\n",
       "      <td>-52.919272</td>\n",
       "      <td>85.232264</td>\n",
       "      <td>67.749220</td>\n",
       "      <td>-73.684130</td>\n",
       "      <td>59.188576</td>\n",
       "      <td>10.678936</td>\n",
       "      <td>-71.297781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.527558</td>\n",
       "      <td>72.266609</td>\n",
       "      <td>-61.935252</td>\n",
       "      <td>39.135978</td>\n",
       "      <td>82.538530</td>\n",
       "      <td>-49.596509</td>\n",
       "      <td>79.223743</td>\n",
       "      <td>43.254091</td>\n",
       "      <td>-69.982489</td>\n",
       "      <td>87.450873</td>\n",
       "      <td>68.400808</td>\n",
       "      <td>-70.703991</td>\n",
       "      <td>61.587452</td>\n",
       "      <td>11.779919</td>\n",
       "      <td>-68.827418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.849928</td>\n",
       "      <td>72.469064</td>\n",
       "      <td>-62.562788</td>\n",
       "      <td>37.988804</td>\n",
       "      <td>82.631347</td>\n",
       "      <td>-50.606259</td>\n",
       "      <td>78.451526</td>\n",
       "      <td>43.567403</td>\n",
       "      <td>-70.658489</td>\n",
       "      <td>86.835388</td>\n",
       "      <td>68.907925</td>\n",
       "      <td>-71.138344</td>\n",
       "      <td>61.686427</td>\n",
       "      <td>11.793440</td>\n",
       "      <td>-68.889316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.329647</td>\n",
       "      <td>71.707275</td>\n",
       "      <td>-63.688956</td>\n",
       "      <td>36.561863</td>\n",
       "      <td>81.868749</td>\n",
       "      <td>-52.752784</td>\n",
       "      <td>86.320630</td>\n",
       "      <td>68.214645</td>\n",
       "      <td>-72.228461</td>\n",
       "      <td>61.596157</td>\n",
       "      <td>11.250648</td>\n",
       "      <td>-68.956425</td>\n",
       "      <td>77.387225</td>\n",
       "      <td>42.717833</td>\n",
       "      <td>-72.015146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.142401</td>\n",
       "      <td>71.435607</td>\n",
       "      <td>-64.177303</td>\n",
       "      <td>36.175818</td>\n",
       "      <td>81.556874</td>\n",
       "      <td>-53.475747</td>\n",
       "      <td>76.986143</td>\n",
       "      <td>42.426849</td>\n",
       "      <td>-72.574743</td>\n",
       "      <td>86.368748</td>\n",
       "      <td>67.901260</td>\n",
       "      <td>-72.444650</td>\n",
       "      <td>61.275402</td>\n",
       "      <td>10.841109</td>\n",
       "      <td>-69.279906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  User         X0         Y0         Z0         X1         Y1  \\\n",
       "1      1     0  54.263880  71.466776 -64.807709  76.895635  42.462500   \n",
       "2      1     0  56.527558  72.266609 -61.935252  39.135978  82.538530   \n",
       "3      1     0  55.849928  72.469064 -62.562788  37.988804  82.631347   \n",
       "4      1     0  55.329647  71.707275 -63.688956  36.561863  81.868749   \n",
       "5      1     0  55.142401  71.435607 -64.177303  36.175818  81.556874   \n",
       "\n",
       "          Z1         X2         Y2         Z2         X3         Y3  \\\n",
       "1 -72.780545  36.621229  81.680557 -52.919272  85.232264  67.749220   \n",
       "2 -49.596509  79.223743  43.254091 -69.982489  87.450873  68.400808   \n",
       "3 -50.606259  78.451526  43.567403 -70.658489  86.835388  68.907925   \n",
       "4 -52.752784  86.320630  68.214645 -72.228461  61.596157  11.250648   \n",
       "5 -53.475747  76.986143  42.426849 -72.574743  86.368748  67.901260   \n",
       "\n",
       "          Z3         X4         Y4         Z4  X5  Y5  Z5  X6  Y6  Z6  X7  Y7  \\\n",
       "1 -73.684130  59.188576  10.678936 -71.297781 NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "2 -70.703991  61.587452  11.779919 -68.827418 NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "3 -71.138344  61.686427  11.793440 -68.889316 NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "4 -68.956425  77.387225  42.717833 -72.015146 NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "5 -72.444650  61.275402  10.841109 -69.279906 NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "   Z7  X8  Y8  Z8  X9  Y9  Z9  X10  Y10  Z10  X11  Y11  Z11  \n",
       "1 NaN NaN NaN NaN NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2 NaN NaN NaN NaN NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3 NaN NaN NaN NaN NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4 NaN NaN NaN NaN NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5 NaN NaN NaN NaN NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78095 entries, 1 to 78095\n",
      "Data columns (total 38 columns):\n",
      "Class    78095 non-null int64\n",
      "User     78095 non-null int64\n",
      "X0       78095 non-null float64\n",
      "Y0       78095 non-null float64\n",
      "Z0       78095 non-null float64\n",
      "X1       78095 non-null float64\n",
      "Y1       78095 non-null float64\n",
      "Z1       78095 non-null float64\n",
      "X2       78095 non-null float64\n",
      "Y2       78095 non-null float64\n",
      "Z2       78095 non-null float64\n",
      "X3       77405 non-null float64\n",
      "Y3       77405 non-null float64\n",
      "Z3       77405 non-null float64\n",
      "X4       74975 non-null float64\n",
      "Y4       74975 non-null float64\n",
      "Z4       74975 non-null float64\n",
      "X5       65072 non-null float64\n",
      "Y5       65072 non-null float64\n",
      "Z5       65072 non-null float64\n",
      "X6       52247 non-null float64\n",
      "Y6       52247 non-null float64\n",
      "Z6       52247 non-null float64\n",
      "X7       38943 non-null float64\n",
      "Y7       38943 non-null float64\n",
      "Z7       38943 non-null float64\n",
      "X8       30563 non-null float64\n",
      "Y8       30563 non-null float64\n",
      "Z8       30563 non-null float64\n",
      "X9       23967 non-null float64\n",
      "Y9       23967 non-null float64\n",
      "Z9       23967 non-null float64\n",
      "X10      14752 non-null float64\n",
      "Y10      14752 non-null float64\n",
      "Z10      14752 non-null float64\n",
      "X11      31 non-null float64\n",
      "Y11      31 non-null float64\n",
      "Z11      31 non-null float64\n",
      "dtypes: float64(36), int64(2)\n",
      "memory usage: 23.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Get an overview of the raw data\n",
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 31 data points appear for the 11th sensor, and are for one user. We will delete this as a feature as it does not provide any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['X11']\n",
    "del df['Y11']\n",
    "del df['Z11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting the Data for Sensor Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for this dataset is formatted with each capture being treated as a separate observation. This makes sense if you are classifying the gesture or user, but we are trying to cluster in order to identify which sensor on the glove corresponds to a specific set of coordinates. Therefore, we must stack the data in order to get a new dataset where each observation has only a single X, Y, and Z coordinate, and corresponds to the specific position of an individual sensor module in any given capture. \n",
    "\n",
    "The original dataset consists of 78,095 captures with coordinates on up to 11 sensors in any given capture, as well as metadata pertaining to the capture about the user and class the capture was representative of. We will retain this metadata, and also create a new variable that corresponds to the sensor number (0 through 10). However, each coordinate will now be labelled as the raw coordinate number on each cartesian axis (X, Y, Z) regardless of sensor number (as opposed to X0, Y10, Z5, etc. as was the case originally).\n",
    "\n",
    "At this point, we will now also drop missing datapoints; NaN values in this dataset represent sensors that were obscured or not recorded for some other reason during a capture, and since we are interested in clustering by sensor, it does not further the analysis to include sensor coordinates for which no data was recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of dataframes with X, Y, Z coordinates selected for each individual sensor (0-10)\n",
    "df_coords = [df.loc[:, ['Class', 'User', 'X%d' % i, 'Y%d' %i, 'Z%d' % i]] for i in range(11)]\n",
    "\n",
    "for i in range(len(df_coords)):\n",
    "    # NaN values are dropped at this time\n",
    "    df_coords[i] = df_coords[i].dropna()\n",
    "    \n",
    "    # Coordinate variable labels will now be standardized\n",
    "    df_coords[i].columns = ['Class', 'User', 'X', 'Y', 'Z']\n",
    "    \n",
    "    # Sensor number will now be added as a variable 'sensor' to each dataset\n",
    "    df_coords[i]['Sensor'] = i\n",
    "    \n",
    "# Combine datasets into new dataframe: df2\n",
    "df2 = pd.concat(df_coords, ignore_index=True)\n",
    "\n",
    "# Reorder columns with metadata columns first\n",
    "df2 = df2[['Class', 'User', 'Sensor', 'X', 'Y', 'Z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the newly formatted dataset, we now have 612,209 distinct cartesian coordinates with corresponding Sensor, Class, and User metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 612209 entries, 0 to 612208\n",
      "Data columns (total 6 columns):\n",
      "Class     612209 non-null int64\n",
      "User      612209 non-null int64\n",
      "Sensor    612209 non-null int64\n",
      "X         612209 non-null float64\n",
      "Y         612209 non-null float64\n",
      "Z         612209 non-null float64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 28.0 MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>User</th>\n",
       "      <th>Sensor</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.263880</td>\n",
       "      <td>71.466776</td>\n",
       "      <td>-64.807709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.527558</td>\n",
       "      <td>72.266609</td>\n",
       "      <td>-61.935252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.849928</td>\n",
       "      <td>72.469064</td>\n",
       "      <td>-62.562788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.329647</td>\n",
       "      <td>71.707275</td>\n",
       "      <td>-63.688956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.142401</td>\n",
       "      <td>71.435607</td>\n",
       "      <td>-64.177303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  User  Sensor          X          Y          Z\n",
       "0      1     0       0  54.263880  71.466776 -64.807709\n",
       "1      1     0       0  56.527558  72.266609 -61.935252\n",
       "2      1     0       0  55.849928  72.469064 -62.562788\n",
       "3      1     0       0  55.329647  71.707275 -63.688956\n",
       "4      1     0       0  55.142401  71.435607 -64.177303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding 2\n",
    "#### 10pts\n",
    "Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Datapoints per User by Class (Hand Gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Print descriptive info for the unique values for each predictor\n",
    "\n",
    "#1=Fist(with thumb out), \n",
    "#2=Stop(hand flat), \n",
    "#3=Point1(point with pointer finger), \n",
    "#4=Point2(point with pointer and middle fingers), \n",
    "#5=Grab(fingers curled as if to grab). \n",
    "\n",
    "print('Class:', list(df2.Class.unique()))\n",
    "print('User:', list(df2.User.unique()))\n",
    "#df_User = df.groupby(['User','Class'])['Class'].count() \n",
    "df_Class = df2.groupby(['Class', 'User'])['User'].count()\n",
    "\n",
    "df_Class['total'] = sum(df_Class) #df_User \n",
    "\n",
    "df_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_Class['total']\n",
    "#plot and format bar chart\n",
    "plt.figure(figsize=(16,5), dpi=80)\n",
    "_ = df_Class.plot(kind='bar')\n",
    "#plt.barh(df_neighborhood, width=0.4, height=0.4, align='center', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of datapoints for each User by Class (Hand Gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "byClass = df2.groupby(['Class'])['User'].count()\n",
    "User_byClass = df2.groupby(['Class','User'])['User'].count()\n",
    "\n",
    "output = User_byClass['Percentage'] = (User_byClass / byClass ) * 100\n",
    "\n",
    "df_output = output.to_frame(\"Percentage\")\n",
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Plotting of User/Class Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set up plotly API key\n",
    "plotly.tools.set_credentials_file(username='danageis', api_key='0NAcrzM8YksRAT3uyEZ7')\n",
    "\n",
    "# Enable offline plots (embed into ipynb)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Define list of possible users\n",
    "possible_users = set(df.User.unique())\n",
    "\n",
    "# Define dictionary of all possible user/class combinations (which ones took pictures of which)\n",
    "possible_classes = {usr: set(df.where(df.User == usr).Class.dropna().unique()) for usr in possible_users}\n",
    "\n",
    "# Define functions to create 3D-interactive plots of each user/position combo\n",
    "def parse_coords(cls=1, usr=1):\n",
    "    \"\"\" Helper function: return all coords for specified User and Class\n",
    "    \n",
    "    cls (int): Class (defaults to 1)\n",
    "    usr (int): User (defaults to 1)\n",
    "    \n",
    "    Ret (dict): {dimension (str): coordinates (pd.Series)}\n",
    "    \"\"\"\n",
    "    dims = ['X', 'Y', 'Z']\n",
    "    fill = lambda suffix: [suffix + str(i) for i in range(1,11)]\n",
    "    cols = {col: fill(col) for col in dims}\n",
    "    coords = {dim: df[cols[dim]].where(df.User == usr).where(df.Class == cls).stack() for dim in dims}\n",
    "    return coords\n",
    "\n",
    "def plot_3d(cls=1, usr=1, title=None, allpts=False, clusters=np.array([0])):\n",
    "    \"\"\" Return 3D interactive plot for given coordinates set (single user/sign combos)\n",
    "    \n",
    "    cls (int): Class (defaults to 1)\n",
    "    usr (int): User (defaults to 1)\n",
    "    title (str): Title of the plot (defaults to \"User {usr} Position {cls}\")\n",
    "    allpts (bool): Whether or not this is meant to cluster all points in the dataset (df2)\n",
    "        All 600k+ points is too many to plot interactively; this will sample 20,000 points randomly and graph them\n",
    "    clusters (np.array): Clusters to use for color-coding (only valid for allpts at this time)\n",
    "    \n",
    "    Ret (plotly.graph_objs.Scatter3d figure object)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure user/class designation is valid\n",
    "    if not usr in possible_users:\n",
    "        return \"ERROR: User %d does not have any data. Try again with a different user specified.\" % usr\n",
    "    elif not cls in possible_classes[usr]:\n",
    "        return \"ERROR: User %d does not have any data for Class %d. Try again with a different class specified.\" % (usr, cls)\n",
    "    \n",
    "    # Process points to draw\n",
    "    if allpts:\n",
    "        # Sample 20,000 random coords w/o replacement\n",
    "        coords = df2.copy()\n",
    "        if clusters.any():\n",
    "            coords['cluster'] = clusters\n",
    "        coords = coords.sample(n=20000, replace=False)\n",
    "    else:\n",
    "        coords = parse_coords(cls, usr)\n",
    "        \n",
    "    # Name plot if title not provided (default behavior)\n",
    "    if not title:\n",
    "        if allpts:\n",
    "            title = \"20,000 Random Points from Dataset\"\n",
    "            if clusters.any():\n",
    "                title += \" (Clustered)\"\n",
    "        else:\n",
    "            title = \"User %d Position %d\" % (usr, cls)\n",
    "\n",
    "    # Color-code clustered points, if provided\n",
    "    if allpts and clusters.any():\n",
    "        marker_params = dict(size=5,\n",
    "                             color=coords.cluster,\n",
    "                             colorscale='Portland'\n",
    "                             )\n",
    "    else:\n",
    "        marker_params = dict(size=5)\n",
    "            \n",
    "    data = [go.Scatter3d(x=coords['X'],\n",
    "                         y=coords['Y'],\n",
    "                         z=coords['Z'],\n",
    "                         mode='markers',\n",
    "                         marker=marker_params\n",
    "                         )\n",
    "            ]\n",
    "\n",
    "    layout = dict(width=800,\n",
    "                  height=700,\n",
    "                  autosize=True,\n",
    "                  title=title,\n",
    "                  scene=dict(xaxis=dict(gridcolor='rgb(255, 255, 255)',\n",
    "                                        zerolinecolor='rgb(255, 255, 255)',\n",
    "                                        showbackground=True,\n",
    "                                        backgroundcolor='rgb(230, 230,230)'\n",
    "                                        ),\n",
    "                             yaxis=dict(gridcolor='rgb(255, 255, 255)',\n",
    "                                        zerolinecolor='rgb(255, 255, 255)',\n",
    "                                        showbackground=True,\n",
    "                                        backgroundcolor='rgb(230, 230,230)'\n",
    "                                        ),\n",
    "                             zaxis=dict(gridcolor='rgb(255, 255, 255)',\n",
    "                                        zerolinecolor='rgb(255, 255, 255)',\n",
    "                                        showbackground=True,\n",
    "                                        backgroundcolor='rgb(230, 230,230)'\n",
    "                                        ),\n",
    "                             camera=dict(up=dict(x=0,\n",
    "                                                 y=0,\n",
    "                                                 z=1\n",
    "                                                 ),\n",
    "                                         eye=dict(x=-1.7428,\n",
    "                                                  y=1.0707,\n",
    "                                                  z=0.7100,\n",
    "                                                  )\n",
    "                                         ),\n",
    "                             aspectratio = dict(x=1,\n",
    "                                                y=1,\n",
    "                                                z=0.7\n",
    "                                                ),\n",
    "                             aspectmode = 'manual'\n",
    "                             ),\n",
    "                )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "\n",
    "    return py.iplot(fig, filename=\"Hands-%s\" % title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_3d(cls=1, usr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 1\n",
    "#### 10 pts\n",
    "Train and adjust parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data, we will be attempting to cluster the data on the basis of the sensors used to collect the data. As described in the business understanding section, this dataset consists of snapshot measurements taken from a special glove fitted with sensors to track a person's hand movements and map them to 3-dimensional space. The dataset has recorded data for up to 11 sensors in each capture (some may have been obscured when measurement was performed), and associated 3D coordinates for each sensor. Captures were taken for 13 users who were performing one of five pre-defined gestures with their hand.\n",
    "\n",
    "Our goal is to cluster each data point based on which of the 11 possible sensors it corresponds to. Each record in the dataset has been formatted so that it represents a single coordinate location for an individual sensor. To accomplish this we will attempt clustering with 11 total clusters defined in our clustering algorithms, ideally corresponding with each of the sensors that is present on the glove. We will begin by performing cluster analysis of all points aggregated together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d(allpts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d(allpts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown above are 2 random samplings of 20,000 points each from the dataset. This was done to illustrate that when multiple random samples are plotted in 3-dimensional space, the distributions are different each time but there are similar patterns that can be observed consistently such as 2 large elliptoid clusters on the right side and some smaller clusters on the left side. This provides some anecdotal evidence that clustering may be successful using all available data aggregated from every user and every gesture class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data set as we have in the two random samples above, it seems that while there are some obvious discrete clusters in 3-dimensional space these clusters are not necessarily uniform globular clusters. These type of clusters might be well defined using Gaussian mixture model clustering which would allow for normally distributed clusters of varying shapes and sizes. We will first attempt to fit a Gaussian mixture model to obtain clusters for the 11 sensors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "# Fit 11 clusters\n",
    "#  Set random state to '123456789' to make sure same result achieved each time\n",
    "gmm = GMM(n_components=11,\n",
    "          random_state=123456789\n",
    "          )\n",
    "gmm_X = df2[['X','Y','Z']]\n",
    "gmm.fit(gmm_X)\n",
    "gmm_clusters = gmm.predict(gmm_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = gmm_X['Z'].astype(float)\n",
    "xdata = gmm_X['X'].astype(float)\n",
    "ydata = gmm_X['Y'].astype(float)\n",
    "_ = ax.scatter3D(gmm_X['X'], gmm_X['Y'], gmm_X['Z'], c=gmm_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_3d(allpts=True, clusters=gmm_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the basic GMM clusters above, both as a static image consisting of all points (more than 600,000) and an interactive plot that is sampled as 20,000 random points from the dataset color-coded by cluster. From these visuals, we can see that there does appear to be decent clustering.\n",
    "\n",
    "From the data description, we know that there are 2 sensors on each finger and 3 sensors on the thumb. We also know that there are several positions in which multiple (sometimes more than half) of the sensors are obscured from view and not recorded. Therefore, this clustering makes sense from a logical perspective, but it could likely still be improved.\n",
    "\n",
    "Another interesting comparison is the distribution of clusters as defined by GMM. While we do not know from the raw data which sensors correspond to which point on the glove, we do know that in a majority of recorded instances there are sensors that were unable to be recorded. It would be interesting to note if this clustering algorithm created clusters of varying sizes, which might be indicative of an uneven distribution of which sensors were not recorded most or least often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note from this distribution that there are significantly varying distributions between clusters. If these clusters do in fact coincide with sensors on the glove, this could provide evidence that certain sensors appear more often than others.\n",
    "\n",
    "This also makes logical sense, since it would be expected that some of the gestures being performed would have obscured at least part of the hand. The distribution shows that from GMM, there are 2 clusters defined that are very scarce in the total (both less than 5%) compared to the rest. This could be accounted for as the 2 sensors present on a finger that is often obscured, such as the pinky finger. Conversely, there are 2 clusters that stand out as about the same percentage as eachother (almost 14%) but both significantly higher than most of the other clusters. These cluster could represent sensors on fingers that are needed to perform most of the gestures recorded, so they might show up regardless of user or class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with the clusters defined as a new variable\n",
    "df_gmm = gmm_X.copy()\n",
    "df_gmm['Clusters'] = gmm_clusters\n",
    "\n",
    "# Count the number of instances in each cluster and convert to a percentage of the total\n",
    "cluster_pcts = df_gmm.groupby('Clusters').count()['X'] / len(gmm_X) * 100\n",
    "\n",
    "# Plot the distribution\n",
    "ax = cluster_pcts.plot(kind='bar', title=\"Percentage of Each GMM-Defined Cluster\")\n",
    "_ = ax.set_ylabel(\"Percentage of Total Points (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we attempt to quantify our clustering in some way so that it can be compared to other methods. While the dataset does include labels for each sensor (X0, X1, X2, etc.), it is stated in the data description that the numbering is arbitrary; sensor X0 in one instance could be tracking a completely different sensor than it is in any other instance. Therefore, we do not know the true sensor identity at any given time and cannot concretely compare against the known sensor identities with a metric such as the adjusted rand score.\n",
    "\n",
    "Nevertheless, a situation such as this is the perfect application for clustering. For this project we will rely on the silhouette metric, which is a measure of the closeness of a point to the average at the center of it's cluster combined with the smallest distance between the same point and the next closest cluster. This metric allows us to quantify the successfulness of our clustering without having to rely on true known measurements. The silhouette score is optimal at 1.0, so higher values are desired. In our case, our 600,000+ records proved too computationally intensive to calculate by force, so a random sample of 50,000 is taken instead. The final metric we be an average of the silhouette score for each of the 50,000 points randomly sampled from our dataset. This metric will allow us to compare the efficacy of GMM to other clustering methods as well as fine-tune the parameters of each cluster model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Get silhouette score\n",
    "gmm_sil = silhouette_score(gmm_X, gmm_clusters, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM Silhouette Score:\", gmm_sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this unoptomized GMM silhouette score as a basseline, we will now adjust parameters in an attempt to optimize the fit of our clusters. Perhaps the most important parameter available for GMM is covariance_type which controls how covariances are treated between clusters. By default, 'full' is used which allows each cluster its own general covariance matrix. This is a good baseline and may prove to be the best method for our data, but since the sensor clustering patterns should be relatively similar it may be beneficial to test another level for the parameter. To this end, we will test 'tied', in which each component shares the same covariance matrix but it is still defined as a general covariance matrix. The other alternatives are 'diagonal' and 'spherical', but these constrain the type of covariance matrix that is possible and we do not believe this would provide a good fit for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit 11 clusters using 'tied' covariance type\n",
    "gmm_tied = GMM(n_components=11,\n",
    "          random_state=123456789,\n",
    "          covariance_type='tied'\n",
    "          )\n",
    "gmm_X_tied = df2[['X','Y','Z']]\n",
    "gmm_tied.fit(gmm_X_tied)\n",
    "gmm_clusters_tied = gmm_tied.predict(gmm_X_tied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get silhouette score\n",
    "gmm_sil_tied = silhouette_score(gmm_X_tied, gmm_clusters_tied, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM (tied) Silhouette Score:\", gmm_sil_tied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the produced silhouette score using the 'tied' parameter, it seems that this covariance type may in fact be beneficial to our clusters. Since this was successful, we will also test 'sphericity' and 'diagonal' to be sure that we are using the optimal method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit 11 clusters using 'spherical' covariance type\n",
    "gmm_sphere = GMM(n_components=11,\n",
    "          random_state=123456789,\n",
    "          covariance_type='spherical'\n",
    "          )\n",
    "gmm_X_sphere = df2[['X','Y','Z']]\n",
    "gmm_sphere.fit(gmm_X_sphere)\n",
    "gmm_clusters_sphere = gmm_sphere.predict(gmm_X_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get silhouette score\n",
    "gmm_sil_sphere = silhouette_score(gmm_X_sphere, gmm_clusters_sphere, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM (spherical) Silhouette Score:\", gmm_sil_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit 11 clusters using 'diag' covariance type\n",
    "gmm_diag = GMM(n_components=11,\n",
    "          random_state=123456789,\n",
    "          covariance_type='diag'\n",
    "          )\n",
    "gmm_X_diag = df2[['X','Y','Z']]\n",
    "gmm_diag.fit(gmm_X_diag)\n",
    "gmm_clusters_diag = gmm_diag.predict(gmm_X_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get silhouette score\n",
    "gmm_sil_diag = silhouette_score(gmm_X_diag, gmm_clusters_diag, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM (diagonal) Silhouette Score:\", gmm_sil_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had predicted, the spherical and diagonal convariance types were too constraining to our clusters and both negatively impacted our silhouette score. Nevertheless, we can now proceed with confidence that the 'tied' covariance type (a shared general covariance matrix) is optimal for our sensor clusters. This parameter will be used for subsequent GMM clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another parameter that may benefit our process in init_params. There must be initial weights, averages, and precisions applied to the dataset before the GMM algorithm can correctly start clustering. This initiation is by default performed by a single round of k-means clustering (with the round specified by n_init).\n",
    "\n",
    "We will test these parameters to see if they increase our silhouette score at all. First we begin by testing random initiation instead of one based on k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit 11 clusters with random initiation\n",
    "gmm_rand = GMM(n_components=11,\n",
    "               random_state=123456789,\n",
    "               covariance_type='tied',\n",
    "               init_params='random'\n",
    "               )\n",
    "gmm_X_rand = df2[['X','Y','Z']]\n",
    "gmm_rand.fit(gmm_X_rand)\n",
    "gmm_clusters_rand = gmm_rand.predict(gmm_X_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get silhouette score\n",
    "gmm_sil_rand = silhouette_score(gmm_X_rand, gmm_clusters_rand, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM (tied, random initialization) Silhouette Score:\", gmm_sil_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One immediate benefit of using random initialization is that the processing down decreased significantly, likely because the initial k-means requires substantial processing that can be mitigated by using a random initialization instead. This is interesting because it suggests that the GMM algorithm itself is quick, but that the initial k-means requires a long time to compute.\n",
    "\n",
    "Regardless, changing from a single k-means initialization to a random one dropped our silhouette score substantially (from 0.27 to 0.21), so we will not be using this method going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last parameter of interest is in some ways the opposite of the previous test; we would now like to see if multiple initiation cycles with k-means will produce a better score than only one. The GMM function will pick the most beneficial initiation out of all the iterations the user specifies. For this test, we will test 3 iterations against our previous GMM of a single k-means iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit 11 clusters with 3 k-means init\n",
    "gmm_3init = GMM(n_components=11,\n",
    "               random_state=123456789,\n",
    "               covariance_type='tied',\n",
    "               init_params='kmeans',\n",
    "               n_init=3\n",
    "          )\n",
    "gmm_X_3init = df2[['X','Y','Z']]\n",
    "gmm_3init.fit(gmm_X_3init)\n",
    "gmm_clusters_3init = gmm_3init.predict(gmm_X_3init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get silhouette score\n",
    "gmm_sil_3init = silhouette_score(gmm_X_3init, gmm_clusters_3init, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM (3 k-means iterations) Silhouette Score:\", gmm_sil_3init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test took slightly longer than the previous clustering steps, as the GMM clustering step took time to process the 3 k-means iterations. It also markedly improved our best score (from 0.27 to almost 0.3, a 10% increase), so we will finally test the same model building step but this time with 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit 11 clusters with 3 k-means init\n",
    "gmm_10init = GMM(n_components=11,\n",
    "               random_state=123456789,\n",
    "               covariance_type='tied',\n",
    "               init_params='kmeans',\n",
    "               n_init=10\n",
    "          )\n",
    "gmm_X_10init = df2[['X','Y','Z']]\n",
    "gmm_10init.fit(gmm_X_10init)\n",
    "gmm_clusters_10init = gmm_10init.predict(gmm_X_10init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get silhouette score\n",
    "gmm_sil_10init = silhouette_score(gmm_X_10init, gmm_clusters_10init, sample_size=50000, random_state=123456789)\n",
    "print(\"Average GMM (10 k-means iterations) Silhouette Score:\", gmm_sil_10init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 10 k-means iterations, this model took considerably longer to cluster, but did not increase our score over 3 iterations at all. This means that the initiation that resulted in the best initial k-means clustering over 10 iterations was also found within the first 3 iterations (at least for the random sample we tested). Therefore, we conclude that 3 iterations of k-means for initialization is ideal for our purposes, since the processing increase is relatively minor but the increase in efficacy is substantial.\n",
    "\n",
    "Based on the preceeding tests, our optimized GMM clustering model has the following parameters:\n",
    "- **tied** covariance type\n",
    "- **kmeans** initiation parameter\n",
    "- **3** initialization iterations\n",
    "\n",
    "Overall, we have found GMM to be a robust clustering algorithm that seems to produce meaningful clusters without much optimization, but slight optimizations can increase the effectiveness of the clustering as shown in our previous tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, ShuffleSplit\n",
    "\n",
    "# Fit 11 clusters\n",
    "kms = KMeans(n_clusters=11, init='k-means++',random_state=1)\n",
    "kms_X = df2[['X','Y','Z']]\n",
    "kms.fit(kms_X)\n",
    "kms_clusters = kms.predict(kms_X)\n",
    "kms_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = kms_X['Z'].astype(float)\n",
    "xdata = kms_X['X'].astype(float)\n",
    "ydata = kms_X['Y'].astype(float)\n",
    "ax.scatter3D(kms_X['X'], kms_X['Y'], kms_X['Z'], c=kms_clusters, s=1)\n",
    "ax.set_title('Gesture points for X, Y, Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d(allpts=True, clusters=kms_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with the clusters defined as a new variable\n",
    "df_kms = kms_X.copy()\n",
    "df_kms['Clusters'] = kms_clusters\n",
    "\n",
    "# Count the number of instances in each cluster and convert to a percentage of the total\n",
    "cluster_pcts = df_kms.groupby('Clusters').count()['X'] / len(df_kms) * 100\n",
    "\n",
    "# Plot the distribution\n",
    "ax = cluster_pcts.plot(kind='bar', title=\"Percentage of Each GMM-Defined Cluster\")\n",
    "_ = ax.set_ylabel(\"Percentage of Total Points (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 2\n",
    "#### 10pts\n",
    "Evaluate and Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n",
    "\n",
    "Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].\n",
    "\n",
    "Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.\n",
    "\n",
    "In this example the silhouette analysis is used to choose an optimal value for n_clusters. The silhouette plot shows that the n_clusters value of 3, 5 and 6 are a bad pick for the given data due to the presence of clusters with below average silhouette scores and also due to wide fluctuations in the size of the silhouette plots. Silhouette analysis is more ambivalent in deciding between 2 and 4.\n",
    "\n",
    "Also from the thickness of the silhouette plot the cluster size can be visualized. The silhouette plot for cluster 0 when n_clusters is equal to 2, is bigger in size owing to the grouping of the 3 sub clusters into one big cluster. However when the n_clusters is equal to 4, all the plots are more or less of similar thickness and hence are of similar sizes as can be also verified from the labelled scatter plot on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Split into X Features & Y Training\n",
    "df2b = df2.copy()\n",
    "df2b = df2b[df2b.User > 12 ] #User 13 & 14\n",
    "df3 = df2b[['X','Y','Z']]\n",
    "X = df3.values[:,]\n",
    "df3s = df2b[['Sensor']]\n",
    "y = df3s.values[:,] \n",
    " \n",
    "\n",
    "# Not done for now\n",
    "range_n_clusters = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=11, init='k-means++',random_state=1)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 3\n",
    "#### 10 pts\n",
    "Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 4\n",
    "#### 20 pts\n",
    "Summarize the Ramifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment \n",
    "#### 10 pts\n",
    "Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work\n",
    "#### 10 pts\n",
    "You have free reign to provide additional analyses or combine analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to Center Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in this dataset is taken with slightly differing points serving as the origin for each coordinate set. Due to this fact, we attempted to center our data somewhat by subtracting the minimum value for each coordinate set corresponding to a given capture. We had hoped that this would allow us to reduce variance and keep points on a more even plane. Unfortunately, the centering method was not successful and we ended up with a lower silhouette score than was obtained otherwise. Nevertheless, we believe that it was incredibly important to the data cleaning process to rule out any potential for improving our dataset prior to clustering, and this method allowed us to rule out one potential change that could have been made to the dataset.\n",
    "\n",
    "##### Chris please change as much as you want, just wanted to get somethind down so we have a good argument for why we should get exceptional work points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data centering\n",
    "this section searches for minimum x,y,z coordinate values and zeroes them and adjusts each coordinate accordingly to reduce variation relative to starting hand position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates new sub dataframes for x y and z coordinates\n",
    "dfx=df[['X0','X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']].copy()\n",
    "dfy=df[['Y0','Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9','Y10']].copy()\n",
    "dfz=df[['Z0','Z1','Z2','Z3','Z4','Z5','Z6','Z7','Z8','Z9','Z10']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculates min value\n",
    "dfx['xmin']=dfx.min(axis=1)\n",
    "dfy['ymin']=dfy.min(axis=1)\n",
    "dfz['zmin']=dfz.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###takes minimum and subtracts form all\n",
    "for a in range(11): \n",
    "    dfx['X%d' % a] = dfx['X%d' % a] - dfx['xmin']\n",
    "    \n",
    "for b in range(11): \n",
    "    dfy['Y%d' % b] = dfy['Y%d' % b] - dfy['ymin']\n",
    "    \n",
    "for c in range(11): \n",
    "    dfz['Z%d' % c] = dfz['Z%d' % c] - dfz['zmin']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove the calculated min values for merging\n",
    "del dfx['xmin']\n",
    "del dfy['ymin']\n",
    "del dfz['zmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create mini dataframe and then concatenate the transformed dataframes\n",
    "dfmini = df.iloc[:,0:2].copy()\n",
    "dfnew= pd.concat([dfmini,dfx, dfy,dfz], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reorder the columns\n",
    "dfnew = dfnew[['Class','User', 'X0','Y0','Z0','X1','Y1','Z1','X2','Y2','Z2','X3','Y3','Z3','X4','Y4','Z4','X5','Y5','Z5',\n",
    "               'X6','Y6','Z6','X7','Y7','Z7','X8','Y8','Z8','X9','Y9','Z9','X10','Y10','Z10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfnew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1=Fist(with thumb out), \n",
    "#2=Stop(hand flat), \n",
    "#3=Point1(point with pointer finger), \n",
    "#4=Point2(point with pointer and middle fingers), \n",
    "#5=Grab(fingers curled as if to grab). \n",
    "\n",
    "#filter certain users for plotting below\n",
    "df_user6 = df[df.User == 6][df.Class == 2]\n",
    "df_user14 = df[df.User == 14][df.Class == 1]\n",
    "df_user5 = df[df.User == 5][df.Class == 4]\n",
    "df_user8 = df[df.User == 8][df.Class == 3]\n",
    "\n",
    "#One row in data table - represnts on set of data points\n",
    "df_row12000 = df[11999:12000][df.Class == 5]\n",
    "\n",
    "# feature categories\n",
    "X_features = ['X0','X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']\n",
    "Y_features = ['Y0','Y1','Y2','Y3','Y4','Y5','Y6','Y7','Y8','Y9','Y10']\n",
    "Z_features = ['Z0','Z1','Z2','Z3','Z4','Z5','Z6','Z7','Z8','Z9','Z10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One record plotted in 3D show Class 5 (Grab Gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one set of markers\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = df_row12000[Z_features].astype(float)\n",
    "xdata = df_row12000[X_features].astype(float)\n",
    "ydata = df_row12000[Y_features].astype(float)\n",
    "ax.scatter3D(xdata, ydata, zdata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All User 6's records plotted in 3D with Posture 3 (Stop sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = df_user6[Z_features].astype(float)\n",
    "xdata = df_user6[X_features].astype(float)\n",
    "ydata = df_user6[Y_features].astype(float)\n",
    "ax.scatter3D(xdata, ydata, zdata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All User 14's records plotted in 3D with Class 1 (Fist Gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = df_user14[Z_features].astype(float)\n",
    "xdata = df_user14[X_features].astype(float)\n",
    "ydata = df_user14[Y_features].astype(float)\n",
    "ax.scatter3D(xdata, ydata, zdata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All User 8's records plotted in 3D with Class 3 (point with pointer finger Gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = df_user8[Z_features].astype(float)\n",
    "xdata = df_user8[X_features].astype(float)\n",
    "ydata = df_user8[Y_features].astype(float)\n",
    "ax.scatter3D(xdata, ydata, zdata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All User 5's records plotted in 3D with Class 5 (Grab Gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata = df_user5[Z_features].astype(float)\n",
    "xdata = df_user5[X_features].astype(float)\n",
    "ydata = df_user5[Y_features].astype(float)\n",
    "ax.scatter3D(xdata, ydata, zdata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All User 5's records plotted in 3D in a Wireframe show Class 2 (Stop Gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_wireframe(df_user6[X_features], df_user6[Y_features], df_user6[Z_features], color='black')\n",
    "ax.set_title('wireframe');\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
