{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the data into variable 'df' from pickled object\n",
    "from funcs import load_df\n",
    "df = load_df()\n",
    "\n",
    "# Get an overview of the raw data\n",
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical variables to the correct datatype\n",
    "categ_features = ['Gender', 'Neighbourhood', 'Scholarship', 'Hipertension', 'Diabetes',\n",
    "                  'Alcoholism', 'Handcap', 'SMS_received', 'No-show'\n",
    "                  ]\n",
    "df[categ_features] = df[categ_features].astype('category')\n",
    "\n",
    "# Pull-out the scheduled time of day as a new variable (ScheduledTime) and re-insert into df\n",
    "df.ScheduledDay, ScheduledTime = df.ScheduledDay.str.split('T', 1).str\n",
    "df.insert(loc=4, column='ScheduledTime', value=ScheduledTime)\n",
    "\n",
    "# Convert date-time variables to the correct type using the C-style fmt codes\n",
    "df.ScheduledDay = pd.to_datetime(df.ScheduledDay, format=\"%Y-%m-%d\")\n",
    "df.ScheduledTime = pd.to_datetime(df.ScheduledTime, format=\"%H:%M:%SZ\").dt.time\n",
    "df.AppointmentDay = pd.to_datetime(df.AppointmentDay, format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# Cast PatientId as int\n",
    "df.PatientId = df.PatientId.astype(np.int64)\n",
    "\n",
    "# Rename incorrect column names.\n",
    "df = df.rename(columns={'Hipertension': 'Hypertension', 'Handcap': 'Handicap', 'SMS_received': 'SMSReceived', 'No-show': 'NoShow'})\n",
    "\n",
    "# Impute the values of sub zero age observations\n",
    "df.Age=df.Age.replace(-1, int(df.Age.median()))\n",
    "\n",
    "# Create a column showing days in advance\n",
    "df['DaysInAdvance']=(df['AppointmentDay']-df['ScheduledDay']).dt.days\n",
    "\n",
    "# Run through the data to ensure no appointments that are scheduled after the appointment(which would be impossible).\n",
    "# If true, scheduled day with the appointment day is assumed as the a same day as the appointment, then recalculate advance field\n",
    "df['ScheduledDay'] = np.where(df['ScheduledDay']>df['AppointmentDay'], df['AppointmentDay'], df['ScheduledDay'])\n",
    "df['DaysInAdvance']=(df['AppointmentDay']-df['ScheduledDay']).dt.days\n",
    "\n",
    "# Create a day of week variable for both the scheduled day and the appointment day which will allows to examining\n",
    "#  any potential trends related to the day of the week and appointment no-show\n",
    "df['ScheduledDOW'] = df['ScheduledDay'].dt.weekday_name\n",
    "df['AppointmentDOW'] = df['AppointmentDay'].dt.weekday_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new variables\n",
    "df['age_range'] = pd.cut(df.Age,[0,16,65,1e6],3,labels=['child','adult','senior']) \n",
    "df = df.replace({'NoShow': {'Yes': 1, 'No': 0}})\n",
    "\n",
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove ID variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove attributes not usefull\n",
    "del df['PatientId']\n",
    "del df['AppointmentID']\n",
    "\n",
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple scatter plot of Continuous Features vs NoShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "sns.lmplot('Age','DaysInAdvance', data=df, hue='NoShow', palette='Set1', fit_reg=True, scatter_kws={\"s\": 70})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: calling describe when not all the data is categorical will cause the \n",
    "# categorical variables to be removed\n",
    "df[['ScheduledDay','ScheduledTime','AppointmentDay',\n",
    "    'Gender','age_range','Neighbourhood','Scholarship',\n",
    "    'Hypertension','Diabetes','Alcoholism','Handicap',\n",
    "    'SMSReceived','ScheduledDOW','AppointmentDOW','NoShow']].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encode Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform one-hot encoding of the categorical data \n",
    "tmp_df = pd.get_dummies(df.Handicap,prefix='Handicap')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.AppointmentDOW,prefix='AppointmentDOW')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.ScheduledDOW,prefix='ScheduledDOW')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "#tmp_df = pd.get_dummies(df.Neighbourhood,prefix='Neighbourhood')\n",
    "#df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.age_range,prefix='age_range')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the current Gender atribute with something slightly more intuitive and readable\n",
    "df['IsMale'] = df.Gender=='male' \n",
    "df.IsMale = df.IsMale.astype(np.int)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's clean up the dataset\n",
    "if 'Gender' in df:\n",
    "    del df['Gender'] # if 'Sex' column still exists, delete it (as we created an ismale column)\n",
    "    \n",
    "if 'Handicap' in df:    \n",
    "    del df['Handicap'] # get reid of the original category as it is now one-hot encoded\n",
    "    \n",
    "if 'ScheduledDOW' in df:    \n",
    "    del df['ScheduledDOW'] # get reid of the original category as it is now one-hot encoded\n",
    "    \n",
    "if 'AppointmentDOW' in df:    \n",
    "    del df['AppointmentDOW'] # get reid of the original category as it is now one-hot encoded\n",
    "\n",
    "if 'Neighbourhood' in df:    \n",
    "    del df['Neighbourhood'] # get reid of the original category as it is now one-hot encoded\n",
    "\n",
    "#remove categorical variables for logistic regression analysis\n",
    "if 'age_range' in df:\n",
    "    del df['age_range']\n",
    "\n",
    "if 'AppointmentID' in df:\n",
    "    del df['AppointmentID']\n",
    "    \n",
    "if 'ScheduledDay' in df:\n",
    "    del df['ScheduledDay']\n",
    "    \n",
    "if 'ScheduledTime' in df:\n",
    "    del df['ScheduledTime']\n",
    "\n",
    "if 'AppointmentDay' in df:\n",
    "    del df['AppointmentDay']\n",
    "    \n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models (50pts))\n",
    "\n",
    "#### Logistic Regression \n",
    "#### Assumptions:\n",
    "<br>-Binary logistic regression requires the dependent variable to be binary.\n",
    "<br>-For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome.\n",
    "<br>-Only the meaningful variables should be included.\n",
    "<br>-The independent variables should be independent of each other. That is, the model should have little or no multicollinearity.\n",
    "<br>-The independent variables are linearly related to the log odds.\n",
    "<br>-Logistic regression requires quite large sample sizes.\n",
    "\n",
    "ref: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['NoShow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='NoShow', data=df, palette='hls')\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_NoShow = len(df[df['NoShow']==0])\n",
    "count_Show = len(df[df['NoShow']==1])\n",
    "pct_of_NoShow = count_NoShow/(count_NoShow+count_Show)\n",
    "print(\"percentage of no shows are\", pct_of_NoShow*100)\n",
    "pct_of_Show = count_Show/(count_NoShow+count_Show)\n",
    "print(\"percentage of shows\", pct_of_Show*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classes are imbalanced, and the ratio of NoShows to Shows instances is 79:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('NoShow').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination\n",
    "Recursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Numpy Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'NoShow' in df:\n",
    "    y = df['NoShow'].values # get the labels we want\n",
    "    del df['NoShow'] # get rid of the class label\n",
    "    X = df.values # use everything else to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "#    have converted them into simple matrices to use with scikit learn\n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, train_size=0.8)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "        #NOTE: as you increase C, test diff values by grid search\n",
    "    #another par is balanced=TRUE/FALSE instead of class weight\n",
    "    \n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "\n",
    "# this does the exact same thing as the above block of code, but with shorter syntax\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    lr_clf.fit(X[train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict(X[test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and here is an even shorter way of getting the accuracies for each training and test set\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we can change some of the parameters interactively\n",
    "from ipywidgets import widgets as wd\n",
    "\n",
    "def lr_explor(cost):\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=cost, class_weight=None) # get object\n",
    "    accuracies = cross_val_score(lr_clf,X,y=y,cv=cv_object) # this also can help with parallelism\n",
    "    print(accuracies)\n",
    "\n",
    "wd.interact(lr_explor,cost=(0.001,5.0,0.05),__manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines \n",
    "\n",
    "Add Chris's SVM here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Advantages (10pts)\n",
    "Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Feature Importance (30pts)\n",
    "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpret the weights\n",
    "\n",
    "# iterate over the coefficients\n",
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = df.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "    \n",
    "# does this look correct? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,df.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# you can apply the StandardScaler function inside of the cross-validation loop \n",
    "#  but this requires the use of PipeLines in scikit. \n",
    "#  A pipeline can apply feature pre-processing and data fitting in one compact notation\n",
    "#  Here is an example!\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) \n",
    "\n",
    "# create the pipline\n",
    "piped_object = Pipeline([('scale', std_scl),  # do this\n",
    "                         ('logit_model', lr_clf)]) # and then do this\n",
    "\n",
    "weights = []\n",
    "# run the pipline cross validated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    piped_object.fit(X[train_indices],y[train_indices])  # train object\n",
    "    # it is a little odd getting trained objects from a  pipeline:\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "\n",
    "error_y=dict(\n",
    "            type='data',\n",
    "            array=np.std(weights,axis=0),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "graph1 = {'x': df.columns,\n",
    "          'y': np.mean(weights,axis=0),\n",
    "    'error_y':error_y,\n",
    "       'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For more improvement and guarding against overfitting:** At this point it would make sense to remove variables that are highly related to one another or ones that are irrelevant and keep going with the weights analysis. What variables would you remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xnew = df[['Age','ScheduledDOW_Saturday','AppointmentDOW_Wednesday']].values\n",
    "\n",
    "weights = []\n",
    "# run the pipline corssvalidated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(Xnew,y)):\n",
    "    piped_object.fit(Xnew[train_indices],y[train_indices])  # train object\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "weights = np.array(weights)\n",
    "\n",
    "error_y=dict(\n",
    "            type='data',\n",
    "            array=np.std(weights,axis=0),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "graph1 = {'x': ['Age','ScheduledDOW_Saturday','AppointmentDOW_Wednesday'],\n",
    "          'y': np.mean(weights,axis=0),\n",
    "    'error_y':error_y,\n",
    "       'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Cross validation is performed using repeated holdout via ShuffleSplit()\n",
    "\n",
    "Ten folds are used\n",
    "The split is: 80% training data and 20% test data\n",
    "A random seed is set so the same random test and training splits are used each time cross validation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=4, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Evaluation\n",
    "The following functions performs cross validation using cross_validate() for classification estimators and returns accuracy, precision, recall, f1 score, and a confusion matrix for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, X, y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv_object, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, X, y, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(y,predictions)\n",
    "    confMat = confusion_matrix(y,predictions)\n",
    "    acc = accuracy_score(y,predictions)\n",
    "    \n",
    "    print(classReport)\n",
    "    print(confMat)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Logisitic regression 5-fold cross-validation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_object # KFolds = 5\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst, X, y, cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EvaluateClassifierEstimator2(classifierEst, X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DANGER SVM ZONE! MOST OF THIS IS STILL BROKE AF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alot of this is broke since i haven't been able to get the main file to run, and some of it is experimental still. Will be dramatically updating and adding analysis. Only section of merit is the try other svm method at bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform one-hot encoding of the categorical data \n",
    "tmp_df2 = pd.get_dummies(df2.Handicap,prefix='Handicap')\n",
    "df2 = pd.concat((df2,tmp_df2),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df2 = pd.get_dummies(df2.AppointmentDOW,prefix='AppointmentDOW')\n",
    "df2 = pd.concat((df2,tmp_df2),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df2 = pd.get_dummies(df2.ScheduledDOW,prefix='ScheduledDOW')\n",
    "df2 = pd.concat((df2,tmp_df2),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Sex atribute with something slightly more intuitive and readable\n",
    "df2['IsMale'] = df2.Gender=='male' \n",
    "df2.IsMale = df2.IsMale.astype(np.int)\n",
    "\n",
    "df2.info()\n",
    "\n",
    "# Now let's clean up the dataset\n",
    "if 'Gender' in df2:\n",
    "    del df2['Gender'] # if 'Sex' column still exists, delete it (as we created an ismale column)\n",
    "    \n",
    "if 'Handicap' in df2:    \n",
    "    del df2['Handicap'] # get reid of the original category as it is now one-hot encoded\n",
    "    \n",
    "if 'ScheduledDOW' in df2:    \n",
    "    del df2['ScheduledDOW'] # get reid of the original category as it is now one-hot encoded\n",
    "    \n",
    "if 'AppointmentDOW' in df2:    \n",
    "    del df2['AppointmentDOW'] # get reid of the original category as it is now one-hot encoded\n",
    "\n",
    "if 'Neighbourhood' in df2:    \n",
    "    del df2['Neighbourhood'] # get reid of the original category as it is now one-hot encoded\n",
    "\n",
    "#remove categorical variables for logistic regression analysis\n",
    "if 'age_range' in df2:\n",
    "    del df2['age_range']\n",
    "\n",
    "if 'AppointmentID' in df2:\n",
    "    del df2['AppointmentID']\n",
    "    \n",
    "if 'ScheduledDay' in df2:\n",
    "    del df2['ScheduledDay']\n",
    "    \n",
    "if 'ScheduledTime' in df2:\n",
    "    del df2['ScheduledTime']\n",
    "\n",
    "if 'AppointmentDay' in df2:\n",
    "    del df2['AppointmentDay']\n",
    "    \n",
    "df2.info() \n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'NoShow' in df2:\n",
    "    y = df2['NoShow'].values # get the labels we want\n",
    "    del df2['NoShow'] # get rid of the class label\n",
    "    X = df2.values # use everything else to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "randtrain=random.sample(train_indices,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train2=X[randtrain]\n",
    "y_train2=y[randtrain]\n",
    "random.sample()\n",
    "randtest=random.sample(train_indices,5000)\n",
    "X_test2=X[randtest]\n",
    "y_test2=y[randtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train2 = X[randtrain]\n",
    "    y_train2 = y[randtrain]\n",
    "    X_test2 = X[randtest]\n",
    "    y_test2 = y[randtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#use same train indicies\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC() # get object\n",
    "svm_clf.fit(X_train2, y_train2)  # train object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat2 = svm_clf.predict(X_test2) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test2,y_hat2)\n",
    "conf = mt.confusion_matrix(y_test2,y_hat2)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try other way for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#use same train indicies\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html \n",
    "notes on this that i'm working on...\n",
    "\n",
    "loss parameters\n",
    "‘hinge’, ‘log’, ‘modified_huber’, ‘squared_hinge’, ‘perceptron’\n",
    "penalty options\n",
    "str, ‘none’, ‘l2’, ‘l1’, or ‘elasticnet’\n",
    "\n",
    "l1 and hinge result in a 0 false prediction, which may have legitimate value from an operational standpoint...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.804035103591785\n",
      "[[17774     0]\n",
      " [ 4332     0]]\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use some compact notation for creating a linear SVM classifier with stichastic descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "regularize_const = 0.1\n",
    "iterations = 5\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter=iterations, n_jobs=-1, penalty='l1')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_indices, test_indices in cv.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_indices]),y[train_indices])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_indices]))\n",
    "    \n",
    "    conf2 = mt.confusion_matrix(y[test_indices],yhat)\n",
    "    acc2 = mt.accuracy_score(y[test_indices],yhat)\n",
    "\n",
    "print('SVM Accuracy:', acc2)\n",
    "print(conf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Support Vectors (10pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
