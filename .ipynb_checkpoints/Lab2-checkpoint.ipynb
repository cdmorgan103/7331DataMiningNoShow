{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "## Medical Patient No Show\n",
    "\n",
    "### Team members: Luay Dajani, Dana Geislinger, Chris Morgan, Caroll Rodriguez\n",
    "##### Github - https://github.com/cdmorgan103/7331DataMiningNoShow\n",
    "\n",
    "MSDS 7331, 10/28/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "import datetime \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import seaborn as sns\n",
    "\n",
    "# Hide deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Load the data into variable 'df' from pickled object\n",
    "from funcs import load_df\n",
    "df = load_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 1\n",
    "#### [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "**Meetings Notes: 10/24 ** Chris - copy from MiniLab\n",
    "Variable to remove - AppointmentID & PatientID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciKitLearn models have difficulty working with complex objects such as datetime.datetime and datetime.time. To account for this, we will store all dates as ordinal values (the number of days since 1/1/1) and all time values as the number of elapsed seconds in the day (1:30PM = 13 * 3600 + 30 * 60)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to ordinal integer values (days since 1/1/1)\n",
    "dt_ord = lambda dt: dt.toordinal()\n",
    "if 'ScheduledDay' in df:\n",
    "    df['ScheduledDayOrdinal'] = df['ScheduledDay'].apply(dt_ord)\n",
    "if 'AppointmentDay' in df:\n",
    "    df['AppointmentDayOrdinal'] = df['AppointmentDay'].apply(dt_ord)\n",
    "\n",
    "# Convert time values to seconds (total seconds since start of day)\n",
    "to_secs = lambda t: t.hour * 3600 + t.minute * 60 + t.second\n",
    "if 'ScheduledTime' in df:\n",
    "    df['ScheduledTimeSeconds'] = df['ScheduledTime'].apply(to_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScheduledDayOrdinal</th>\n",
       "      <th>ScheduledTimeSeconds</th>\n",
       "      <th>AppointmentDayOrdinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>736083</td>\n",
       "      <td>67088</td>\n",
       "      <td>736083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736083</td>\n",
       "      <td>58107</td>\n",
       "      <td>736083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>736083</td>\n",
       "      <td>58744</td>\n",
       "      <td>736083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736083</td>\n",
       "      <td>62971</td>\n",
       "      <td>736083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736083</td>\n",
       "      <td>58043</td>\n",
       "      <td>736083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ScheduledDayOrdinal  ScheduledTimeSeconds  AppointmentDayOrdinal\n",
       "0               736083                 67088                 736083\n",
       "1               736083                 58107                 736083\n",
       "2               736083                 58744                 736083\n",
       "3               736083                 62971                 736083\n",
       "4               736083                 58043                 736083"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ScheduledDayOrdinal', 'ScheduledTimeSeconds', 'AppointmentDayOrdinal']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110527 entries, 0 to 110526\n",
      "Columns: 115 entries, ScheduledDay to IsMale\n",
      "dtypes: bool(1), datetime64[ns](2), int32(1), int64(7), object(1), uint8(103)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Remove attributes not usefull\n",
    "del df['PatientId']\n",
    "del df['AppointmentID']\n",
    "\n",
    "# perform one-hot encoding of the categorical data \n",
    "tmp_df = pd.get_dummies(df.Handicap,prefix='Handicap')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.AppointmentDOW,prefix='AppointmentDOW')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.ScheduledDOW,prefix='ScheduledDOW')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.Neighbourhood,prefix='Neighbourhood')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.age_range,prefix='age_range')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Gender attribute with something slightly more intuitive and readable\n",
    "df['IsMale'] = df.Gender=='M' \n",
    "df.IsMale = df.IsMale.astype(np.int)\n",
    "\n",
    "# Now let's clean up the dataset\n",
    "if 'Gender' in df:\n",
    "    del df['Gender'] # if 'Sex' column still exists, delete it (as we created an ismale column)\n",
    "    \n",
    "if 'Handicap' in df:    \n",
    "    del df['Handicap'] # get rid of the original category as it is now one-hot encoded\n",
    "    \n",
    "if 'ScheduledDOW' in df:    \n",
    "    del df['ScheduledDOW'] # get rid of the original category as it is now one-hot encoded\n",
    "    \n",
    "if 'AppointmentDOW' in df:    \n",
    "    del df['AppointmentDOW'] # get rid of the original category as it is now one-hot encoded\n",
    "\n",
    "if 'Neighbourhood' in df:    \n",
    "    del df['Neighbourhood'] # get rid of the original category as it is now one-hot encoded\n",
    "\n",
    "if 'age_range' in df:\n",
    "    del df['age_range']\n",
    "\n",
    "if 'AppointmentID' in df:\n",
    "    del df['AppointmentID']\n",
    "    \n",
    "#if 'ScheduledDay' in df:\n",
    "    #del df['ScheduledDay']\n",
    "    \n",
    "#if 'ScheduledTime' in df:\n",
    "    #del df['ScheduledTime']\n",
    "\n",
    "#if 'AppointmentDay' in df:\n",
    "    #del df['AppointmentDay']\n",
    "\n",
    "# Get an overview of the raw data\n",
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                               int64\n",
      "Scholarship                       int64\n",
      "Hypertension                      int64\n",
      "Diabetes                          int64\n",
      "Alcoholism                        int64\n",
      "SMSReceived                       int64\n",
      "NoShow                             bool\n",
      "DaysInAdvance                     int64\n",
      "Handicap_0                        uint8\n",
      "Handicap_1                        uint8\n",
      "Handicap_2                        uint8\n",
      "Handicap_3                        uint8\n",
      "Handicap_4                        uint8\n",
      "AppointmentDOW_Monday             uint8\n",
      "AppointmentDOW_Tuesday            uint8\n",
      "AppointmentDOW_Wednesday          uint8\n",
      "AppointmentDOW_Thursday           uint8\n",
      "AppointmentDOW_Friday             uint8\n",
      "AppointmentDOW_Saturday           uint8\n",
      "AppointmentDOW_Sunday             uint8\n",
      "ScheduledDOW_Monday               uint8\n",
      "ScheduledDOW_Tuesday              uint8\n",
      "ScheduledDOW_Wednesday            uint8\n",
      "ScheduledDOW_Thursday             uint8\n",
      "ScheduledDOW_Friday               uint8\n",
      "ScheduledDOW_Saturday             uint8\n",
      "ScheduledDOW_Sunday               uint8\n",
      "Neighbourhood_AEROPORTO           uint8\n",
      "Neighbourhood_ANDORINHAS          uint8\n",
      "Neighbourhood_ANTÔNIO HONÓRIO     uint8\n",
      "                                  ...  \n",
      "Neighbourhood_PRAIA DO CANTO      uint8\n",
      "Neighbourhood_PRAIA DO SUÁ        uint8\n",
      "Neighbourhood_REDENÇÃO            uint8\n",
      "Neighbourhood_REPÚBLICA           uint8\n",
      "Neighbourhood_RESISTÊNCIA         uint8\n",
      "Neighbourhood_ROMÃO               uint8\n",
      "Neighbourhood_SANTA CECÍLIA       uint8\n",
      "Neighbourhood_SANTA CLARA         uint8\n",
      "Neighbourhood_SANTA HELENA        uint8\n",
      "Neighbourhood_SANTA LUÍZA         uint8\n",
      "Neighbourhood_SANTA LÚCIA         uint8\n",
      "Neighbourhood_SANTA MARTHA        uint8\n",
      "Neighbourhood_SANTA TEREZA        uint8\n",
      "Neighbourhood_SANTO ANDRÉ         uint8\n",
      "Neighbourhood_SANTO ANTÔNIO       uint8\n",
      "Neighbourhood_SANTOS DUMONT       uint8\n",
      "Neighbourhood_SANTOS REIS         uint8\n",
      "Neighbourhood_SEGURANÇA DO LAR    uint8\n",
      "Neighbourhood_SOLON BORGES        uint8\n",
      "Neighbourhood_SÃO BENEDITO        uint8\n",
      "Neighbourhood_SÃO CRISTÓVÃO       uint8\n",
      "Neighbourhood_SÃO JOSÉ            uint8\n",
      "Neighbourhood_SÃO PEDRO           uint8\n",
      "Neighbourhood_TABUAZEIRO          uint8\n",
      "Neighbourhood_UNIVERSITÁRIO       uint8\n",
      "Neighbourhood_VILA RUBIM          uint8\n",
      "age_range_child                   uint8\n",
      "age_range_adult                   uint8\n",
      "age_range_senior                  uint8\n",
      "IsMale                            int32\n",
      "Length: 112, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>SMSReceived</th>\n",
       "      <th>DaysInAdvance</th>\n",
       "      <th>Handicap_0</th>\n",
       "      <th>Handicap_1</th>\n",
       "      <th>Handicap_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighbourhood_SÃO CRISTÓVÃO</th>\n",
       "      <th>Neighbourhood_SÃO JOSÉ</th>\n",
       "      <th>Neighbourhood_SÃO PEDRO</th>\n",
       "      <th>Neighbourhood_TABUAZEIRO</th>\n",
       "      <th>Neighbourhood_UNIVERSITÁRIO</th>\n",
       "      <th>Neighbourhood_VILA RUBIM</th>\n",
       "      <th>age_range_child</th>\n",
       "      <th>age_range_adult</th>\n",
       "      <th>age_range_senior</th>\n",
       "      <th>IsMale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.089218</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.197246</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.321026</td>\n",
       "      <td>10.183792</td>\n",
       "      <td>0.979724</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>0.028337</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.234060</td>\n",
       "      <td>0.645598</td>\n",
       "      <td>0.120342</td>\n",
       "      <td>0.350023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.109921</td>\n",
       "      <td>0.297675</td>\n",
       "      <td>0.397921</td>\n",
       "      <td>0.258265</td>\n",
       "      <td>0.171686</td>\n",
       "      <td>0.466873</td>\n",
       "      <td>15.254924</td>\n",
       "      <td>0.140942</td>\n",
       "      <td>0.134662</td>\n",
       "      <td>0.040657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127811</td>\n",
       "      <td>0.132541</td>\n",
       "      <td>0.147167</td>\n",
       "      <td>0.165934</td>\n",
       "      <td>0.037059</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>0.423412</td>\n",
       "      <td>0.478334</td>\n",
       "      <td>0.325362</td>\n",
       "      <td>0.476979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age    Scholarship   Hypertension       Diabetes  \\\n",
       "count  110527.000000  110527.000000  110527.000000  110527.000000   \n",
       "mean       37.089218       0.098266       0.197246       0.071865   \n",
       "std        23.109921       0.297675       0.397921       0.258265   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%        18.000000       0.000000       0.000000       0.000000   \n",
       "50%        37.000000       0.000000       0.000000       0.000000   \n",
       "75%        55.000000       0.000000       0.000000       0.000000   \n",
       "max       115.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          Alcoholism    SMSReceived  DaysInAdvance     Handicap_0  \\\n",
       "count  110527.000000  110527.000000  110527.000000  110527.000000   \n",
       "mean        0.030400       0.321026      10.183792       0.979724   \n",
       "std         0.171686       0.466873      15.254924       0.140942   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       0.000000       4.000000       1.000000   \n",
       "75%         0.000000       1.000000      15.000000       1.000000   \n",
       "max         1.000000       1.000000     179.000000       1.000000   \n",
       "\n",
       "          Handicap_1     Handicap_2      ...        \\\n",
       "count  110527.000000  110527.000000      ...         \n",
       "mean        0.018475       0.001656      ...         \n",
       "std         0.134662       0.040657      ...         \n",
       "min         0.000000       0.000000      ...         \n",
       "25%         0.000000       0.000000      ...         \n",
       "50%         0.000000       0.000000      ...         \n",
       "75%         0.000000       0.000000      ...         \n",
       "max         1.000000       1.000000      ...         \n",
       "\n",
       "       Neighbourhood_SÃO CRISTÓVÃO  Neighbourhood_SÃO JOSÉ  \\\n",
       "count                110527.000000           110527.000000   \n",
       "mean                      0.016611                0.017887   \n",
       "std                       0.127811                0.132541   \n",
       "min                       0.000000                0.000000   \n",
       "25%                       0.000000                0.000000   \n",
       "50%                       0.000000                0.000000   \n",
       "75%                       0.000000                0.000000   \n",
       "max                       1.000000                1.000000   \n",
       "\n",
       "       Neighbourhood_SÃO PEDRO  Neighbourhood_TABUAZEIRO  \\\n",
       "count            110527.000000             110527.000000   \n",
       "mean                  0.022148                  0.028337   \n",
       "std                   0.147167                  0.165934   \n",
       "min                   0.000000                  0.000000   \n",
       "25%                   0.000000                  0.000000   \n",
       "50%                   0.000000                  0.000000   \n",
       "75%                   0.000000                  0.000000   \n",
       "max                   1.000000                  1.000000   \n",
       "\n",
       "       Neighbourhood_UNIVERSITÁRIO  Neighbourhood_VILA RUBIM  age_range_child  \\\n",
       "count                110527.000000             110527.000000    110527.000000   \n",
       "mean                      0.001375                  0.007699         0.234060   \n",
       "std                       0.037059                  0.087409         0.423412   \n",
       "min                       0.000000                  0.000000         0.000000   \n",
       "25%                       0.000000                  0.000000         0.000000   \n",
       "50%                       0.000000                  0.000000         0.000000   \n",
       "75%                       0.000000                  0.000000         0.000000   \n",
       "max                       1.000000                  1.000000         1.000000   \n",
       "\n",
       "       age_range_adult  age_range_senior         IsMale  \n",
       "count    110527.000000     110527.000000  110527.000000  \n",
       "mean          0.645598          0.120342       0.350023  \n",
       "std           0.478334          0.325362       0.476979  \n",
       "min           0.000000          0.000000       0.000000  \n",
       "25%           0.000000          0.000000       0.000000  \n",
       "50%           1.000000          0.000000       0.000000  \n",
       "75%           1.000000          0.000000       1.000000  \n",
       "max           1.000000          1.000000       1.000000  \n",
       "\n",
       "[8 rows x 111 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple export of final dataset\n",
    "df.to_csv(\"./data/df.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 2\n",
    "#### [5 points] Describe the ﬁnal dataset that is used for classiﬁcation/regression (include a description of any newly formed variables you created).\n",
    "**Meetings Notes 10/24:** Chris - copy from MiniLab\n",
    "\n",
    "**Meeting Notes: ????** Luay wants add a field that ranks the patient's no show history. If they showed up twice and didn't show up 1 would be 33%. Create a temp dataset to group Patient and determine the # of no shows then merge the dataset and build the ranking. \n",
    "\n",
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1\n",
    "\n",
    "#### [10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "**Meetings Notes 10/24:** Chris - copy from MiniLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2\t\n",
    "\n",
    "#### [10 points]\tChoose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "**Meeting Notes:** Dana - to figure out error with SMOTE\n",
    "Caroll to run CV on Training Set and evaluate the accuracy of Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partioning Data\n",
    "We want to forecast future NoShows based on Appointment dates. We take the data we have and build a fixed training period in the past up to the last month. The last month of data will be used as testing dataset. Before we deploy the model we will rerun the models utilizing the entire dataset to predict the future outcomes.\n",
    "This approach fits our dataset since we there is correlation between the appoointme date and whether or not they no-show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing set --- hold 1 month of data out as test set based on AppointmentDay\n",
    "df_test = df.copy()\n",
    "\n",
    "if 'ScheduledDay' in df_test:\n",
    "    del df_test['ScheduledDay']\n",
    "    \n",
    "if 'ScheduledTime' in df_test:\n",
    "    del df_test['ScheduledTime']\n",
    "\n",
    "X_test = df_test[(df_test['AppointmentDay'] >= datetime.date(2016,5,25))]\n",
    "\n",
    "y_test = X_test['NoShow'].values # get the labels we want.\n",
    "\n",
    "if 'NoShow' in X_test:\n",
    "    del X_test['NoShow'] # get rid of the class label\n",
    "\n",
    "#Training set -- all records less than appointment date 5/1/2016\n",
    "df_train = df.copy()\n",
    "X_train = df_train[(df_train['AppointmentDay'] < datetime.date(2016,5,25))]\n",
    "  \n",
    "y_train = X_train['NoShow'].values # get the labels we want.\n",
    "del X_train['NoShow'] # get rid of the class label\n",
    "\n",
    "if 'NoShow' in X_train:\n",
    "    del X_train['NoShow'] # get rid of the class label\n",
    "\n",
    "df_tmp = df.copy()\n",
    "X = df_tmp\n",
    "y = df_tmp['NoShow']\n",
    "if 'NoShow' in X:\n",
    "    del X['NoShow'] # get rid of the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Prediciting Features:  (110527, 114)\n",
      "Number of Response:  (110527,)\n",
      "Appointment Date Range (Trainig Set):  2016-04-29 00:00:00 2016-05-24 00:00:00\n",
      "Number of Training Records:  (71374, 114)\n",
      "Number of Test Records:  (39153, 112)\n",
      "Appointment Date Range (Test Set):  2016-05-25 00:00:00 2016-06-08 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print ('Number of Prediciting Features: ', X.shape)\n",
    "print ('Number of Response: ', y.shape)\n",
    "print ('Appointment Date Range (Trainig Set): ', min(X_train['AppointmentDay']) ,  max(X_train['AppointmentDay']))\n",
    "print ('Number of Training Records: ', X_train.shape)\n",
    "print ('Number of Test Records: ', X_test.shape)\n",
    "print ('Appointment Date Range (Test Set): ', min(X_test['AppointmentDay']) ,  max(X_test['AppointmentDay']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using SMOTE to perform over-sampling for balancing response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-824ab7b2b948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mX_train_ovr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_ovr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Proportion of response in train set using SMOTE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python37-32\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecate_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32mc:\\program files (x86)\\python37-32\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\program files (x86)\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "# Over-sampling using SMOTE to balance the NoShows\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#Training set -- all records less than appointment date 5/1/2016\n",
    "df_train = df.copy()\n",
    "X_train = df_train\n",
    "\n",
    "y_train = X_train['NoShow'].values # get the labels we want.\n",
    "del X_train['NoShow'] # get rid of the class label\n",
    "\n",
    "if 'NoShow' in X_train:\n",
    "    del X_train['NoShow'] # get rid of the class label\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_ovr, y_train_ovr = sm.fit_sample(X_train, y_train.ravel())\n",
    "print(\"Proportion of response in train set using SMOTE\")\n",
    "for i in np.unique(y_train) :\n",
    "    print(\"The number of {} is {} accouting for {}%.\".format(i, np.bincount(y_train)[i], np.round(np.bincount(y_train)[i]/len(y_train), 3)*100 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby(['AppointmentDay']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.groupby(['AppointmentDay']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Showing below that our time series is pretty well stationary over time except for Saturday which show consistantly lower no show appointments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NoShow'] = df['NoShow']\n",
    "df['NoShow_num'] = np.where(df['NoShow']==True, 1, 0)\n",
    "\n",
    "#Set dataframe with index as Appointment Day\n",
    "ts = df[['AppointmentDay', 'NoShow'] ]\n",
    "ts = df.set_index('AppointmentDay')\n",
    "ts.groupby(['AppointmentDay'])['NoShow'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot below shows the # of NoShow appointmets over time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts.groupby(['AppointmentDay'])['NoShow'].sum(), color=\"purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3\n",
    "\n",
    "#### [20 points] Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "\n",
    "**Meeting Notes**: \n",
    "**Luay (Recursive Feature Elimination for Logistic) here**\n",
    "\t1. Logistic Caroll to move from MiniLab \n",
    "\t2. RandomForest - Chris\n",
    "\t3. XGBoost/Gradient - Caroll\n",
    "\n",
    "Response Gender\n",
    "**Caroll to split training/text with Gender variable**\n",
    "**Luay (Recursive Feature Elimination for Logistic) here**\n",
    "\t1. Logistic Caroll to move from MiniLab\n",
    "\t2. Random -- Chris\n",
    "\t3. XGBoost/Gradient-- Caroll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4\n",
    "\n",
    "#### [10 points] Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "**Meeting Notes**  Precision, recall, F-measure, ROC, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 5\n",
    "\n",
    "#### [10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 6\n",
    "\n",
    "#### [10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment (5 points total) \n",
    "\n",
    "#### How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (10 points total) \n",
    "\n",
    "#### You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?\n",
    "\n",
    "**Meeting Notes** - We did this in MiniLab 1 with chart \n",
    "Possible to add Naives Bayes classification (Luay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
